\chapter{Анализ предметной области}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Классификация САРР}
Системы автоматического распознавания речи (САРР, англ. ASR -- Auto matic Speech Recognition) помогают машинам интерпретировать устную речь и автоматизировать задачи человека, например поиск в интернете, набор текста и тд. Одним из наиболее сложных моментов в разработке таких систем является довольно широкая междисциплинарность задачи, то есть затрагиваются вопросы теории обработки сигналов, математического анализа, психологии, теории коммуникаций, а также лингвистики.

Системы автоматического распознавания речи можно классифицировать по основным аспектам \cite{classif}.К таким аспектам можно отнести следующие. 
\begin{itemize}
	\item Тип речи
	\begin{itemize}
		\item Спонтанная речь.
		
		Спонтанную речь можно рассматривать как речь, которая звучит естественно (с эмоциями, с внезапными паузами).
		
		\item Непрерывная речь. 
		
		Непрерывная речь -- это обычная человеческая речь без пауз между словами. Этот вид значительно затрудняет машинное понимание речи.
		
		\item Связные слова.
		
		Такие слова требуют минимальные паузы между высказываниями. Речь должна течь плавно.
		
		\item Изолированная речь.
		
		Такие системы направлены на распознавания конкретных голосовых команд, получаемых от пользователя.
		
	\end{itemize}
	
	\item Размер словаря.
	\begin{itemize}
		\item Маленькие словари.
		
		САРР с маленькими словарями (чаще до 500-1000 слов) необходимы для распознавания команд, получаемых от пользователя.
		
		\item Большие словари.
		
		Такие словари чаще всего используются в САРР слитной речи. Размеры достигают до десятков тысяч слов \cite{babin}.
	\end{itemize}
	
	\item Персонализация.
	\begin{itemize}
		\item Дикторозависимые.
		
		К классу систем, зависящих от диктора относятся системы, которые требуют предварительного обучения и в его процессе настраиваются на определенного диктора. При смене диктора в таких системах возникает необходимость полной перенастройки. 
		
		\item Дикторонезависимые.
		
		К классу систем, независимых от диктора относятся системы, которые 	работают вне зависимости от того, кто выступает в качестве диктора. Данные системы имеют возможность распознания речи любого диктора и не нуждаются в предварительном обучении.
		
	\end{itemize}
	\item Структурные единицы. 
	
	В качестве структурных единиц могут выступать фразы, слова, фонемы. Системы, которые распознают речь, используя целые слова или фразы, называются системами распознавания речи по шаблону. Создание таких систем менее трудоемко, чем системы основанные на базе выделения лексических элементов (в таких системах структурными единицами являются фонемы). 
	
	\item Принцип выделения структурных единиц.
	
	В современных САРР используются несколько подходов для выделения структурных единиц из потока речи. 
	\begin{itemize}
		\item Фурье-анализ. 
		
		Данный анализ предполагает разложение исходной периодической функции в ряд, в результате чего исходная функция может быть представлена как суперпозиция синусоидальных волн различной частоты \cite{fur_veivlet}.
		\item Вейвлет-анализ (от англ. wavelet -- <<маленькая волна>>). 
		
		Данный анализ раскладывает исходный сигнал в базис функций, которые характеризуют как частоту, так и время \cite{fur_veivlet}.
		\item Кепстральный анализ. 
		
		Данный анализ основан на выделении кепстральных коэффициентов на мел-шкале, называемых мел-частотными кепстральными коэффециентами. Кепстр -- это дискретно-косинусное преобразование амплитудного спектра сигнала в логарифмическом масштабе. Мел -- единица высоты звука \cite{kepstr}.
	\end{itemize}
	
	\item Механизм распознавания
	\begin{itemize}
		\item Скрытые Марковские модели (СММ).
		
		СММ -- это модель, состоящая из $N$ состояний, в каждом система может принимать одно из $M$ значений какого-либо параметра. Матрицей $A = a_{ij}$ задаются вероятности переходов между состояниями из $i$ состояния в $j$ состояние. Вектором $B = {b_j (k)}$ задается вероятность выпадения какого-либо из $M$ значений параметра в каждом из $N$ состояний (выпадения $k$ значения параметра в $j$ состоянии). Вероятность того, что в начальные момент система окажется в $i$ состоянии определяется вектором $\pi = {\pi_i}$. Таким образом, СММ называется тройка $\lambda = ({A, B, \pi})$.  
		
		Модель называется <<скрытой>>, потому что последовательность, в которой пребывала система неважна. Другими словами такая система выступает в роли <<черного ящика>>, на вход которого поступает последовательность параметров, а на выход ожидаем модель, которая с максимальной вероятностью генерирует такую последовательность.
		
		\item Динамическое искажение времени.
		
		Алгоритм динамического искажения времени (Dynamic Time \newline Warping – DTW) является методикой эластичного сравнения вектора наблюдений с хранящимся шаблоном. По-другому можно сказать, что это мера подобия временных рядов, которая минимизирует эффекты временного сдвига, различного течения времени, а также обеспечивает непрерывное преобразование временных рядов для того, чтобы обнаружить одинаковые формы с различными фазами.
		
		\item Нейронные сети.
		
		С помощью нейронных сетей можно создавать самообучаемые и обучаемые системы распознавания речи. Некоторые факторы, которым должны отвечать такие системы: возможность контроля своих действий с последующей коррекцией, разработка системы заключается только в построении архитектуры системы.
		
	\end{itemize}
	
	\item Назначение
	\begin{itemize}
		\item Командные системы.
		
		Такие системы используют распознавания по шаблону (фразе или слову).
		
		\item Системы диктовки.
		
		Такие системы требуют более точного распознавания, то есть выделение лексических элементов. Также при интерпретации произнесенной фразы система полагается не только на то, что произносилось в данный момент, но и на фразы, сказанные ранее.
		
	\end{itemize}
\end{itemize}

Обобщив все выше перечисленное можно представить классификацию систем распознования речи на рисунке \ref{fig:xray3}.

\begin{figure}[h!]
	\includegraphics[pages=-, scale=0.9]{./inc/img/2.pdf}
	\caption{Связь между частотой звука и его высотой}  
	\label{fig:xray3}
\end{figure}
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Основные характеристики речевых сигналов}
Все особенности речевых сигналов можно условно разделить на то, что схоже у определенного состава людей, например, отношение к какой-либо языковой группе, и на то, что индивидуально для каждого человека -- особенности, выраженные в физической индивидуальности речи, произношении, тембре голоса. \cite{chastot} \cite{chastot2}

Для того, чтобы сформировать перечень спектральных \footnote{Спектр сигнала — это совокупность простых составляющих сигнала с определенными амплитудами, частотами и начальными фазами.\cite{spektr}} характеристик в расчет берется только первая гармоника \footnote{Гармоники — это высокочастотные сигналы, накладываемые на основную частоту, то есть частоту цепи, и которые достаточны для искажения формы волны.\cite{spektr}}. 

В соответствии с измеряемой величиной основные спектральные характеристики разделены на следующие группы. \cite{chastot} \cite{chastot2} \cite{signal}
\begin{enumerate}
	\item Частотные характеристики.
	\begin{enumerate}
		\item Частота основного тона -- частота первой гармоники спектра (Гц\footnote{Герц (Гц, Hz) -- единица частоты периодических процессов.}).
		\item Период основного тона (мс).
		\item Количество побочных гармоник (Гц).
		\item Нижняя и верхняя частота спектра (Гц).
		\item Частотный диапазон (Гц).
		\item Частота максимального уровня спектральной плотности (Гц).
	\end{enumerate}
	\item Энергетические характеристики речи.
	\begin{enumerate}
		\item Нижний уровень громкости речи (дБ\footnote{Децибел (дб) --  относительная единица измерения, соответствующая одной десятой бел (В).}).
		\item Верхний уровень громкости речи (дБ).
		\item Динамический диапазон (дБ).
		\item Амплитуда основного тона (дБ).
	\end{enumerate}
	\item Временные характеристики речи.
	\begin{enumerate}
		\item длительность звука речи (мс).
		\item длительность пауз речи между словами/фразами (мс).
		\item скорость звуков речи (звуков/с).
		\item темп речи (слов/мин).
		\item плотность речи -- отношение времени наличия звука к
		полному времени речевого сигнала (\%).
	\end{enumerate}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Методы извлечения речевых характеристик}
В системах распознавания речи одну из главных ролей играет извлечение признаков (частотной характеристики), при этом характеристики сигналов возбуждения чаще всего отбрасываются. 

Извлечение признаков -- это процесс удаления ненужной и избыточной информации и сохранение только полезной информации. Цель такого действия состоит в том, чтобы определить набор свойств (параметры), путем обработки формы сигнала поступившего на вход системе.  Извлечение признаков включает процесс преобразования речевых сигналов в цифровую форму и измерение важных характеристик сигнала, например, энергии или частоты, и дополнение этих измерений значимыми производными измерениями. \cite{isvparam1} \cite{isvparam2}.

Методы извлечения признаков удобно применять при обработке речи с неправильным произношением звуков, так как их можно адаптировать, извлекая нужные параметры, которые потребуются в дальнейшем.

\subsection{Линейно-предсказывающее кодирование}
Линейно-предсказывающее кодирование (англ. Linear prediction coding (LPC)).

%Линейное предсказание уже продолжительное время остается одним из основных подходов к задачам цифровой обработки речи. 

Принцип метода линейного предсказания состоит в том, что участок речевого сигнала можно аппроксимировать линейной комбинацией предыдущих участков сигнала. Предполагается, что речь создается возбуждением линейного изменяющегося во времени фильтра (речевого тракта) случайным шумом для невокализованных речевых сегментов или последовательностью импульсов для голосовой речи \cite{methodisb}.

Процесс речеорбразования описывается линейной системой с переменными параметрами и передаточной функцией \footnote{Передаточной функцией называется отношение изображения выходного воздействия к изображению входного при нулевых начальных условиях. \cite{peredfunc}} \eqref{H}.
\begin{equation}
\label{H}
H(z) = \frac{G}{1 - \sum_{k = 1}^{p} a_k z^{-k}},
\end{equation}
где $G$ -- коэффициент усиления, $a_k$ -- коэффициент предсказания, $p$ -- порядок линейного предсказания.

Зависимость $n$-го отсчета речевого сигнала $s(n)$ от сигнала возбуждения $u(n)$ выражается в виде \eqref{s}
\begin{equation}
\label{s}
s(n) = \sum_{k = 1}^{p} a_k s(n - k) + G u(n)
\end{equation}

Линейный предсказатель с коэффициентами $a_k$ представляется в виде системы с сигналом на выходе, который рассчитывается по формуле \eqref{s1}
\begin{equation}
	\label{s1}
	s(n) = \sum_{k = 1}^{p} a_k s(n - k)
\end{equation}

Суть данного метода заключается в нахождении \textit{линейных коэффициентов предсказания} по речевому сигналу с минимизацией погрешности, которую можно определить по формуле \eqref{s3}
\begin{equation}
	\label{s3}
	e(n) = s(n) - \sum_{k = 1}^{p} a_k s(n - k)
\end{equation}

Недостатком этого метода является то, что он сильно зависит от точности произношения. Поэтому, можно сказать, что данный метод не подходит для решения задачи распознавания речи у людей с дефектами речи.

\subsection{Мэл-частотные кепстральные коэффициенты} \label{1}
Мэл-частотные кепстральные \footnote{Кепстр (cepstrum) — это результат дискретного косинусного преобразования от логарифма амплитудного спектра сигнала.} коэффициенты (англ. Mel frequency \newline Cepstral Coefficient (MFCC)).

Мел \footnote{Мел -- единица высоты звука.}-частотный анализ представляет частоты речи с позиции психоакустического параметра слуха – высоты тона. Высота тона определяет, насколько высоким или низким кажется тон слушателю. Связь между частотой звука и его высотой представлена на рисунке \ref{fig:xray}. \cite{methodisb} \cite{methodisb2}

Перевод частоты из Герц в Мел осуществляется по формуле  \eqref{s1}
\begin{equation}
	\label{s1}
	Mel(f) = 2595 * \log_{10}{1 + \frac{f}{700}},
\end{equation}
где $f$ -- частота в Герцах, $Mel$ -- частота в мелах.

\begin{figure}[h!]
	\includegraphics[pages=-]{./inc/img/1.pdf}
	\caption{Связь между частотой звука и его высотой}  
	\label{fig:xray}
\end{figure}

Пусть $N_{FB}$ — количество фильтров (обычно используют порядка 24 фильтров), ($f_{low}$ , $f_{high}$ ) — исследуемый диапазон частот. Тогда данный диапазон переводят в шкалу мел, разбивают на $N_{FB}$ равномерно распределенных частей и вычисляют соответствующие границы в области линейных частот. 

В конце всех преобразований к коэффициентам приминается дискретное косинусное преобразование, которое рассчитывается по формуле 

Положительные моменты при использовании кепстральных коэффициентов:
\begin{itemize}
	\item спектр проецируется на специальную Мел-шкалу, позволяя выделить наиболее значимые для восприятия человеком частоты;
	\item количество вычисляемых коэффициентов может быть ограничено любым значением.
\end{itemize}


	
\subsection{Кепстральные коэффициенты на основе линейного предсказания} \label{2}
Кепстральные коэффициенты на основе линейного предсказания (англ. Linear prediction cepstral coefficient (LPCC)). 

Метод LPCC похож на MFCC во многом, но главное отличие в том, что он использует линейную шкалу перевода частоты звука в его высоту, воспринимаемую мозгом. Этот способ хорошо работает в области низких частот, так как в этой зоне зависимость высоты звука от его частоты практически линейна. Данная особенность позволяет достичь схожих	результатов при извлечении признаков в области низких частот. \cite{methodisb}


Суть линейного предсказания заключается в том, что линейной комбинацией некоторого количества предшествующих отсчётов можно аппроксимировать текущий отсчёт, то есть
\begin{equation}
	\label{H}
	x(n) = \sum_{k = 1}^{p} a_k x_{n-k},
\end{equation}
где $a_k$ -- коэффициент предсказания, $p$ -- порядок линейного предсказания.

На основе полученных коэффициентов линейного предсказания рассчитываются кепстральные коэффициенты по формуле \eqref{s5}. Причём таких коэффициентов может быть сгенерировано больше, чем самих коэффициентов линейного предсказания.
\begin{equation}
	\label{s5}
	c_n = \left\{\begin{matrix}
		a_n + \sum_{k=1}^{n-1} \frac{k}{n} c_k a_{n-k}& 1\leq n\leq p\\ 
		\sum_{k=n-p}^{n-1} \frac{k}{n} c_k a_{n-k}& n>p
	\end{matrix}\right.
\end{equation}

%Алгоритм можно разделить на несколько этапов:
%\begin{enumerate}
%	\item Речевой сигнал проходит предобработку фильтром, который усиливает высокие частоты спектра, которые в свою очередь уменьшаются в процессе воспроизведения речи.
%	\item Сигнал делится на одинаковые последовательные перекрывающиеся временные участки -- фреймы. С помощью преобразования Фурье для каждого участка находится среднее значение частот.
%	\item Производится математические вычисления, а именно берется логарифм от полученного ранее значения и выполняется дискретное косинусное преобразование.
%\end{enumerate}
	
Например, для сигнала может быть использовано около 12 коэффициентов линейного предсказания, из которых может быть получено порядка 18 кепстральных коэффициентов. \cite{methodisb2}



\subsection{Дискретное вейвлет-преобразование}
Дискретное вейвлет-преобразование (Discrete Wavelet Transform (DWT)).

Для наиболее информативного анализа сложных реальных сигналов необходима обработка как по частотным, так и по временным характеристикам, а также достоверное представление уровней детализации для обнаружения закономерностей. 

При обработке данных в современных пакетах математической обработки данных может выполняться дискретизированная\footnote{Дискретизация — в общем случае — представление непрерывной функции дискретной совокупностью её значений при разных наборах аргументов. \cite{diskretiz}} версия непрерывного вейвлет-преобразования с заданием дискретных значений параметров $(a, b)$ вейвлетов\footnote{<<Вейвлет>> (wavelet) в переводе с английского означает <<маленькая (короткая) волна>>.} с произвольным шагом $\Delta a$ и $\Delta b$.

Результатом является избыточное количество коэффициентов, которое намного превосходит число коэффициентов, которые могут использоваться для выявления тонких особенностей исследуемых сигналов. 

Дискретное вейвлет-преобразование оперирует с дискретными значениями параметров а и b, которые задаются, как правило, в виде степенных функций \eqref{f1}
\begin{equation}
	\label{f1}
	a = a_0 ^{(-m)}, b = k * a_0 ^{(-m)}
\end{equation}
где $m$ -- параметр масштаба, $k$ -- параметр сдвига.

Число использованных вейвлетов по масштабному коэффициенту $m$ задает уровень декомпозиции сигнала, при этом за нулевой уровень $(m = 0)$ обычно принимается сам сигнал.

%Идея применения вейвлетов состоит в многомасштабной обработке сигнала, т. е. в анализе сигнала в разном увеличении с разной степенью детализации.  \cite{methodisb2} \cite{signal2}

Недостатком вейвлет-преобразований можно считать их относительную сложность расчетов. 

Достоинством можно считать детальный разбор поступающего сигнала, что позволяет выявить множество тонких моментов. Именно поэтому данный метод подходит для решения задачи распознавания речи у людей с дефектами речи больше, чем методы, описанные в разделах \ref{1} и \ref{2}.
